{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import database\n",
    "import helper\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = utils.CustomLogger(\"CustomLogger\", log_level= \"info\", display_loglevel= False, display_datetime= False)\n",
    "PICKLE_LIB = utils.PickleLib(data_path=\"./data\", logger= LOG)\n",
    "JIRA = \"Jira\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = database.connect()\n",
    "db = client.JiraRepos\n",
    "collection = db[JIRA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInRange():\n",
    "    results = collection.aggregate([\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"fields.summary\": {\n",
    "                    \"$exists\": True, \n",
    "                    \"$type\": \"string\"\n",
    "                },\n",
    "                \"$expr\": {\n",
    "                    \"$and\": [\n",
    "                        {\"$lt\": [{\"$strLenCP\": \"$fields.summary\"}, 70]},\n",
    "                        {\"$gt\": [{\"$strLenCP\": \"$fields.summary\"}, 39]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sample\": {\n",
    "                \"size\": 5\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    return results\n",
    "\n",
    "def getShorter():\n",
    "    results = collection.aggregate([\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"fields.summary\": {\n",
    "                    \"$exists\": True, \n",
    "                    \"$type\": \"string\"\n",
    "                },\n",
    "                \"$expr\": {\n",
    "                    \"$and\": [\n",
    "                        {\"$lt\": [{\"$strLenCP\": \"$fields.summary\"}, 39]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sample\": {\n",
    "                \"size\": 5\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    return results\n",
    "\n",
    "def getLonger():\n",
    "    results = collection.aggregate([\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"fields.summary\": {\n",
    "                    \"$exists\": True, \n",
    "                    \"$type\": \"string\"\n",
    "                },\n",
    "                \"$expr\": {\n",
    "                    \"$and\": [\n",
    "                        {\"$gt\": [{\"$strLenCP\": \"$fields.summary\"}, 70]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sample\": {\n",
    "                \"size\": 10\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "\n",
    "# results = getInRange()\n",
    "# results = getShorter()\n",
    "results = getLonger()\n",
    "\n",
    "for document in results:\n",
    "    summary.append(document)\n",
    "    print(\"Id: \" + str(document['id']) + \" Length: \" + str(len(document['fields']['summary'])) + \": \" + document['fields']['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKeysByCode(data, target_code):\n",
    "    matching_keys = []\n",
    "    for key, value in data.items():\n",
    "        if 'code' in value and value['code'] == target_code:\n",
    "            matching_keys.append(key)\n",
    "    return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('issueTypeMapping.json') as f:\n",
    "    mappedIssueTypes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedTypes = findKeysByCode(mappedIssueTypes[JIRA], 'Bug Report')\n",
    "mappedTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = []\n",
    "results = collection.aggregate([\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"fields.description\": {\n",
    "                \"$exists\": True, \n",
    "                \"$type\": \"string\",\n",
    "                \"$regex\": \"Steps to\"\n",
    "            },\n",
    "            \"fields.issuetype.name\": {\n",
    "                \"$in\": mappedTypes\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sample\": {\n",
    "            \"size\": 30\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "for document in results:\n",
    "    tickets.append(document)\n",
    "    print(\"Id\", document['id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticket Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Globals ###\n",
    "LOG.reset()\n",
    "FOLDERNAME = \"examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_df = PICKLE_LIB.pickle_load(\"./jiraEvolutions/load_evolution_dataframe(jiras=[_\"+JIRA+\"_])\", 'gzip')\n",
    "# evo_df = PICKLE_LIB.pickle_load(\"./jiraEvolutions/load_evolution_dataframe(sample_data_n=10000)\", 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickets = evo_df[evo_df[\"jira\"]== JIRA]\n",
    "# bugReports = tickets[tickets[\"data_to\"].isin(mappedTypes)]\n",
    "# sample_id = bugReports['issue_id'].values[3]\n",
    "sample_id = tickets[12]['id']\n",
    "samples = evo_df[evo_df[\"issue_id\"] == sample_id]\n",
    "sample = samples[samples[\"jira\"]== JIRA]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionStep = 0\n",
    "ticket = helper.createTicket(sample, evolutionStep)\n",
    "ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ticket['Description'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticket PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessTickets(ticket):\n",
    "    \n",
    "    ### Convert CreatedDate and ResolvedDate to datetime\n",
    "    c_date = ticket['CreatedDate'].values[0]\n",
    "    c_dt_obj = datetime.strptime(c_date, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    ticket['CreatedDate'] = c_dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    r_date = ticket['ResolvedDate'].values[0]\n",
    "    r_dt_obj = datetime.strptime(r_date, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    ticket['ResolvedDate'] = r_dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    ### Convert IssueId to Int\n",
    "    id = ticket['IssueId'].values[0]\n",
    "    ticket['IssueId'] = int(id)\n",
    "\n",
    "preprocessTickets(ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.saveTicket(FOLDERNAME, ticket, evolutionStep, JIRA, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotateTicket(ticket, annotation, reason):\n",
    "    try:\n",
    "        ticket['ViolationActual'] = annotation\n",
    "        ticket['ViolationReason'] = reason\n",
    "        print(\"Annotation successful.\")\n",
    "    except:\n",
    "        print(\"Annotation failed.\")\n",
    "\n",
    "annotateTicket(ticket, \"TRUE\", \"\"\"1. Resolution has to be set from 'None' to 'Low Priority'.\n",
    "                           2. Status has to be set from 'Open' to 'Resolved'.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\"):\n",
    "    dataset = pd.read_csv(\"./data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\")\n",
    "    print(\"The dataset already exists.\")\n",
    "else:\n",
    "    dataset = pd.DataFrame(columns=['Jira', 'IssueId', 'EvoId', 'Summary', 'Description', 'VersionsAffected', 'IssueType', 'Project', 'Components', 'CreatedDate', 'ResolvedDate', 'Status', 'Priority', 'Creator', 'Reporter', 'Resolution', 'IssueLinks', 'Labels','VersionsFixed', 'Assignee', 'TimeSpent', 'Comments', 'ViolationActual', 'ViolationReason', 'FieldCount', 'Fields'])\n",
    "    print(\"The dataset was created successfully.\")\n",
    "\n",
    "dataset = pd.concat([dataset, ticket], ignore_index=True)\n",
    "\n",
    "dataset.to_csv(\"data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\", index=False)\n",
    "print(\"The ticket was inserted into the dataset successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/' + FOLDERNAME + '/' + FOLDERNAME + 'Dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bug Report Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotateTicket(ticket, annotation, reason):\n",
    "    try:\n",
    "        ticket['SmellActual'] = annotation\n",
    "        ticket['SmellReason'] = reason\n",
    "        print(\"Annotation successful.\")\n",
    "    except:\n",
    "        print(\"Annotation failed.\")\n",
    "\n",
    "#annotateTicket(ticket, \"3\", \"\"\"No previous structure. The model has to generate a new structure from scratch.\"\"\")\n",
    "annotateTicket(ticket, \"2\", \"\"\"The structure contains some parts, but is not \"complete\".\"\"\")\n",
    "#annotateTicket(ticket, \"1\", \"\"\"The structure contains all important parts or was only been slightly modified.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\"):\n",
    "    dataset = pd.read_csv(\"./data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\")\n",
    "    print(\"The dataset already exists.\")\n",
    "else:\n",
    "    dataset = pd.DataFrame(columns=['Jira', 'IssueId', 'EvoId', 'Summary', 'Description', 'VersionsAffected', 'IssueType', 'Project', 'Components', 'CreatedDate', 'ResolvedDate', 'Status', 'Priority', 'Creator', 'Reporter', 'Resolution', 'IssueLinks', 'Labels','VersionsFixed', 'Assignee', 'TimeSpent', 'Comments', 'ViolationActual', 'ViolationReason', 'FieldCount', 'Fields'])\n",
    "    print(\"The dataset was created successfully.\")\n",
    "\n",
    "dataset = pd.concat([dataset, ticket], ignore_index=True)\n",
    "\n",
    "dataset.to_csv(\"data/\" + FOLDERNAME + \"/\" + FOLDERNAME + \"Dataset.csv\", index=False)\n",
    "print(\"The ticket was inserted into the dataset successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/' + FOLDERNAME + '/' + FOLDERNAME + 'Dataset.csv')\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
