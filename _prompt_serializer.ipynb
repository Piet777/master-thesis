{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a look at this guides:\n",
    "- (Korzynski, Mazurek, Krzypkowska, & Kurasinski, 2023)\n",
    "\n",
    "Use Template pattern for output format promtp\n",
    "- (White, Fu, Hays, Sandborn, Olea, Gilbert, Elnashar, Spencer-Smith, & Schmidt, 2023)\n",
    "\n",
    "Use PB Smells form Qamar et Al 2021 (see overleaf chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_temp = \"\"\"### Instruction ###\n",
    "Act as a professional {role} working with issue trackers like Jira or Azure DevOps.\n",
    "Working with these issue trackers, you must consider multiple text-based best practices to increase understandability and reduce time.\n",
    "Your outputs should correspond to those a {role} would regarding the ticket.\n",
    "We want to revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
    "\n",
    "### Context ###\n",
    "A ticket consists of multiple fields. You are provided with the fields and a short description for each field.\n",
    "Assignee: The person responsible to resolve the issue.\n",
    "Comments: Community discussion on the issue, including author, timestamp, and content.\n",
    "Components: Project components to which the issue belongs.\n",
    "CreatedDate: The time and date the issue was created.\n",
    "Creator: The person who created the issue.\n",
    "Description: A detailed description of the issue.\n",
    "IssueLinks: A list of links to related issues.\n",
    "IssueType: The issue's purpose within the organization.\n",
    "Labels: Labels to which this issue relates.\n",
    "Priority: The issue importance in relation to other issues.\n",
    "Project: The parent project to which the issue belongs.\n",
    "Reporter: The person who found/reported the issue.\n",
    "Resolution: A record of the issue's resolution, once resolved or closed.\n",
    "ResolvedDate: The time and date the issue was resolved.\n",
    "Status: The stage the issue is currently at in its lifecycle.\n",
    "Summary: A brief one-line summary of the issue.\n",
    "TimeSpent: Amount of time spent working on the issue.\n",
    "VersionsAffected: The versions of the project affected by the issue.\n",
    "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
    "\n",
    "### Best Practice ###\n",
    "The best practice to check is {best_practice}\"\"\"\n",
    "init_prompt = PromptTemplate(template= init_temp, input_variables= [\"role\", \"best_practice\"])\n",
    "\n",
    "init_prompt.save(\"prompts/init/initPrompt_V2.1.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_temp =\"\"\"Best Practice: Update Missing/Outdated Fields\n",
    "During the evolution of a ticket, some fields may have become outdated or missing.\n",
    "You could find the needed information in the \"Summary\", \"Description\", or \"Comments\" fields.\n",
    "Get contextual knowledge about the ticket through the \"Summary\", \"Description\", and \"Comments\" fields.\n",
    "If someone specifically mentions or suggests a change for the ticket in the \"Comments\" field, update the ticket accordingly.\n",
    "The change can be provided by a human or as a message from a programm.\n",
    "Ignore error messages, logs and quotes within the comment.\n",
    "Possible keywords for such a change are: \"edit\", \"change\", \"move\", \"mark\", \"fix\", \"set\", \"update\", \"modify\", \"correct\", \"adjust\", \"resolve\" and \"should\".\n",
    "Pay particular attention to the most recent comments.\n",
    "\n",
    "Return only mentioned or suggested changes from the \"Comments\" field.\"\"\"\n",
    "\n",
    "update_prompt = PromptTemplate(template= update_temp, input_variables= [])\n",
    "update_prompt.save(\"prompts/update/updatePrompt_V1.26.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output format prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_format_temp =\"\"\"### Instruction ###\n",
    "You receive changes and recommendations made to fields of a ticket from an issue tracker.\n",
    "Return the data  in the following format as JSON-format:\n",
    "\"<violation_predicted>\": \"<Set to TRUE, if a change was detected and made, otherwise FALSE>\",\n",
    "\"fields\": \"<Contains the list for the receives changes, icnluding <field>, <recommendation>, and <reason>>\"\n",
    "\"field\": \"<name of updated field>\", \n",
    "\"changed_to\": \"<the new input of the field after update, without any explanation>\", \n",
    "\"reason\": \"<reason for the update>\"\n",
    "\n",
    "### Context ###\n",
    "Data: {revised_ticket}\"\"\"\n",
    "\n",
    "update_format_prompt = PromptTemplate(template= update_format_temp, input_variables= [\"revised_ticket\"])\n",
    "\n",
    "update_format_prompt.save(\"prompts/update/updateFormatPrompt_V1.12.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Length Prompt (Best Practice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examples:\n",
    "- https://bugzilla.mozilla.org/page.cgi?id=bug-writing.html\n",
    "- https://bugs.eclipse.org/bugs/page.cgi?id=bug-writing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_temp = \"\"\"'Summary Length':\n",
    "Your Task is to check if the ticket summary has exactly between {min} and {max} characters.\n",
    "If the number of characters is exactly in this range, return the original summary.\n",
    "Otherwise, recommend a new summary that number of characters is exactly in this range based on the information of the description field for the ticket.\n",
    "\n",
    "The ticket is in JSON format.\n",
    "Ticket: {ticket}\"\"\"\n",
    "\n",
    "sumLen_prompt = PromptTemplate(template= sumLen_temp, input_variables= [\"min\", \"max\", \"ticket\"])\n",
    "\n",
    "sumLen_prompt.save(\"prompts/summary/summaryLengthPrompt_V3.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot CoT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_0ShotCoT_temp = \"\"\"Best Practice: Summary Length\n",
    "Your Task is to check if the ticket summary has exactly between {min} and {max} characters.\n",
    "If the number of characters is exactly in this range, return the original summary.\n",
    "Otherwise, recommend a new summary that number of characters is exactly in this range based on the information of the description field for the ticket.\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "sumLen_0ShotCoT_prompt = PromptTemplate(template= sumLen_0ShotCoT_temp, input_variables= [\"min\", \"max\"])\n",
    "\n",
    "sumLen_0ShotCoT_prompt.save(\"prompts/summary/summaryLengthPrompt_0ShotCoT_V1.0.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"minChar\": 39,\n",
    "        \"maxChar\": 70,\n",
    "        \"input\": \"\"\"{{'Summary':'Sourcetree crashes',\n",
    "'Description':'Source tree crashes everytime i open , I have uninstalled and installed many times',\n",
    "'VersionsAffected':'3.4.4',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Sourcetree for Windows',\n",
    "'Components':'Git'}}\"\"\",\n",
    "        \"output\": \"\"\"The current summary is \"Sourcetree crashes\", which consists of 18 characters. This is below the recommended range of 39 to 70 characters for a summary.\n",
    "\n",
    "Recommended Summary: \"Sourcetree crashes upon opening repeatedly\"\n",
    "\n",
    "This revised summary is 42 characters long, fitting within the recommended range and succinctly conveying the essence of the ticket.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"minChar\": 39,\n",
    "        \"maxChar\": 70,\n",
    "        \"input\": \"\"\"{{'Summary':'Opening and closing Sourcetree causes Pageant to crash\\/close',\n",
    "'Description':'I have installed putty and pageant outside of Sourcetree, and I have Pageant startup during OS boot so my key-file is always ready.\\r\\n\\r\\nDidn't quite notice it at first, so not sure which version it started at, but Sourcetree now causes Pageant to crash\\/close when it opens or closes, causing e.g. git commands and such from command line to suddenly start to failing for no apparent reason.\\r\\n\\r\\nWhenever I open or close Sourcetree now, I have to reopen Pageant and reload my key, including entering a long passkey. Super annoying. Sourcetree shouldn't close or cause any other applications to crash when it opens or when it closes.\\r\\n\\r\\nIt happens on all 3 computers of mine. All running latest Windows, latest Pageant, and latest Sourcetree.',\n",
    "'VersionsAffected':'3.4.4',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Sourcetree for Windows',\n",
    "'Components':'General'}}\"\"\",\n",
    "        \"output\": \"\"\"The current summary is \"Opening and closing Sourcetree causes Pageant to crash\\/close\" which consists of 61 characters. This is within the best practice range of 39 to 70 characters.\n",
    "\n",
    "No summary has to be recommended. \n",
    "\n",
    "The original summary is compliant with the best practice for summary length and does not require any changes.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"minChar\": 39,\n",
    "        \"maxChar\": 70,\n",
    "        \"input\": \"\"\"{{'Summary':'Cannot change title of News tool',\n",
    "'Description':'After initially setting up the News tool during worksite setup, I tried to go to the option page (NEWS-2) and change the title of the tool. After I made the change, the title of the tool did not update, even after I logged out and logged back in. However, when I opened up options, the new title that I had entered was still specified.\\n\\nI tried to change the URL of the feed as well as the title at the same time, and even though the new feed was displayed properly, the title of the tool remained what I had initially set it to during worksite setup.',\n",
    "'VersionsAffected':'2.0',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Sakai',\n",
    "'Components':'News (RSS)'}}\"\"\",\n",
    "        \"output\": \"\"\"The current summary is \"Cannot change title of News tool\", which consists of 32 characters. This is below the recommended range of 39 to 70 characters for a summary.\n",
    "\n",
    "Recommended Summary: \"Title of News tool remains unchanged after several update attempts\"\n",
    "\n",
    "This revised summary is 66 characters long, fitting within the recommended range and succinctly conveying the essence of the ticket.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"minChar\": 39,\n",
    "        \"maxChar\": 70,\n",
    "        \"input\": \"\"\"{{'Summary':'Game Crashes When Player Opens Inventory While Respawning with 'Immediate Respawn' Enabled',\n",
    "'Description':'If the player opens their inventory quickly after respawning in a world with 'Immediate Respawn' enabled, the world will crash. This happened accidentally once in one of my worlds. I tried it a few more times after reloading, and it seemed to happen reliably as long as I opened my inventory at the right time.',\n",
    "'VersionsAffected':'PS4 1.89',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Minecraft Console Edition',\n",
    "'Components':null}}\"\"\",\n",
    "        \"output\": \"\"\"The current summary is \"Game Crashes When Player Opens Inventory While Respawning with 'Immediate Respawn' Enabled\", which consists of 90 characters. This exceeds the recommended range of 39 to 70 characters for a summary.\n",
    "\n",
    "Recommended Summary: \"Crash on inventory access with active 'Immediate Respawn' on respawn\"\n",
    "\n",
    "This revised summary is 68 characters long, fitting within the recommended range and succinctly conveying the essence of the ticket.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"minChar\": 39,\n",
    "        \"maxChar\": 70,\n",
    "        \"input\": \"\"\"{{'Summary':'Epic link gets removed when moving an epic from a non next gen project to a next project',\n",
    "'Description':'h3. Summary \\r\\n\\r\\n When an epic from a non next-Gen project is moved to a next-Gen project, the association is removed. All issues associated with the epics will  no longer be linked to the epic \\r\\n\\r\\n h3. Steps to reproduce \\r\\n\\r\\n # Have 2 projects (Next-gen and non next-gen) \\r\\n # Create an Epic from a non Next-gen project \\r\\n # Add a child issue to the epic \\r\\n # Move the epic to the next-gen project \\r\\n\\r\\n h3. Expected Result \\r\\n Epic link remains. The issues are still linked with the epic in the next-gen project even after the moved. \\r\\n\\r\\n h3. Actual Result \\r\\n Epic link is lost',\n",
    "'VersionsAffected':null,\n",
    "'IssueType':'Bug',\n",
    "'Project':'Jira Software Cloud',\n",
    "'Components':'next-gen'}}\"\"\",\n",
    "        \"output\": \"\"\"The current summary is \"Epic link gets removed when moving an epic from a non next gen project to a next project\", which consists of 88 characters. This exceeds the recommended range of 39 to 70 characters for a summary.\n",
    "\n",
    "Recommended Summary: \"Epic link loss on moving an epic to a 'next-gen' project\"\n",
    "\n",
    "This revised summary is 56 characters long, fitting within the recommended range and succinctly conveying the essence of the ticket.\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_FewShot_temp = PromptTemplate(\n",
    "    input_variables=[\"minChar\", \"maxChar\", \"input\", \"output\"], \n",
    "    template=\"\"\"'Summary Length':\n",
    "Your Task is to check if the ticket summary has exactly between {minChar} and {maxChar} characters.\n",
    "If the number of characters is exactly in this range, return the original summary.\n",
    "Otherwise, recommend a new summary that number of characters is exactly in this range based on the information of the description field for the ticket.\n",
    "\n",
    "The ticket is in JSON format.\n",
    "Ticket: {input}\n",
    "Answer: {output}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_FewShot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=sumLen_FewShot_temp,\n",
    "    suffix= \"\"\"'Summary Length':\n",
    "Your Task is to check if the ticket summary has exactly between {min} and {max} characters.\n",
    "If the number of characters is exactly in this range, return the original summary.\n",
    "Otherwise, recommend a new summary that number of characters is exactly in this range based on the information of the description field for the ticket.\n",
    "\n",
    "The ticket is in JSON format.\n",
    "Ticket: {ticket}\n",
    "Answer: \"\"\",\n",
    "    input_variables=[\"min\", \"max\", \"ticket\"],\n",
    ")\n",
    "\n",
    "sumLen_FewShot_prompt.save(\"prompts/summary/summaryLengthPrompt_FewShot_V2.3.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output format prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_format_temp = \"\"\"### Instruction ###\n",
    "You receive a revised ticket from an issue tracker in JSON format.\n",
    "Return the given Data in the following format in JSON:\n",
    "\"<violation_predicted>\": \"<Set to TRUE, if a change was detected and made, otherwise FALSE>\"\n",
    "\"<summary_old>\": \"<The current and unchanged content of the summary field>\"\n",
    "\"<summary_new>\": \"<The recommended and revised content of the summary field>\"\n",
    "\n",
    "If the summary was not changed, return the original and unchanged summary in the \"<summary_new>\" field.\n",
    "Don't return any source code or code snippets.\n",
    "\n",
    "### Context ###\n",
    "Data: {revised_ticket}\"\"\"\n",
    "\n",
    "sumLen_format_prompt = PromptTemplate(template= sumLen_format_temp, input_variables= [\"revised_ticket\"])\n",
    "\n",
    "sumLen_format_prompt.save(\"prompts/summary/summaryLengthFormatPrompt_V1.5.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbitrary Structure Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Best Practice: Description Completeness\n",
    "The received ticket is from type \"{issue_type}\".\n",
    "Your Task is to check if the \"Description\" field of the ticket is complete.\n",
    "We define a description as complete if it contains the following pieces:\n",
    "{content}\n",
    "Role: abstract behavior of actors in the system context; describes who uses the system.\n",
    "Task: specific things that must be done to achieve goals; solution or function of the problem.\n",
    "Capability: the ability of actors to achieve goals based on certain conditions and events.\n",
    "Goal: a condition or a circumstance desired by stakeholders or actors; describes the problem domain or the impact of solving the problem.\n",
    "\n",
    "The general format of a {issue_type} can be expressed as follows: \n",
    "{strucutre}\n",
    "As a <Role>, I want <Task>, So that <Goal>.\n",
    "\n",
    "If the description is complete, return the original description.\n",
    "Otherwise, recommend a new description for the ticket.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descComp_temp = \"\"\"Best Practice: Arbitrary Structure\n",
    "The received ticket is from the superior type \"{issue_type}\".\n",
    "Your Task is to check if the \"Description\" field of the ticket contains all components of a given structure.\n",
    "The components of the desired structure are described as follows:\n",
    "{structure_desc}\n",
    "\n",
    "The desired strucutre of a {issue_type} is as follows: \n",
    "{strucutre}\n",
    "\n",
    "If the description is conatins all components, return the original description.\n",
    "If the description contains nothing, return \"No description provided.\".\n",
    "Otherwise, recommend a new description, suitable to the desired structure for the ticket.\n",
    "\"\"\"\n",
    "\n",
    "descComp_prompt = PromptTemplate(template= descComp_temp, input_variables= [\"issue_type\", \"structure_desc\", \"structure\"])\n",
    "\n",
    "descComp_prompt.save(\"prompts/arbitraryStructure/arbitraryStructurePrompt_V1.0.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output format prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descComp_format_temp = \"\"\"### Instruction ###\n",
    "You receive a revised ticket from an issue tracker in JSON format.\n",
    "Return the given Data in the following format in JSON:\n",
    "\"<violation_predicted>\": \"<TRUE, if a violation was detectd, otherwise FALSE>\"\n",
    "\"<description_old>\": \"<Old version of the content of the description field>\"\n",
    "\"<description_new>\": \"<New version of the content of the description field>\"\n",
    "\n",
    "If the description was not changed, return the original description in the \"<description_new>\" field.\n",
    "Don't return any source code or code snippets.\n",
    "\n",
    "### Context ###\n",
    "Data: {revised_ticket}\"\"\"\n",
    "\n",
    "descComp_format_prompt = PromptTemplate(template= descComp_format_temp, input_variables= [\"revised_ticket\"])\n",
    "\n",
    "descComp_format_prompt.save(\"prompts/arbitraryStructure/arbitraryStructureFormatPrompt_V1.0.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Speech Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we find that including the term “ethnic slur” in our prompt greatly improves the performance because this term specifies the victims to be a group. Using\n",
    "“offensive or toxic content” as prompt doesn’t indi- cate the target of the victim, and thus leads to poor performance. \n",
    "\n",
    "LLMs cannot understand “hatespeech” is targeting a specific group, and thus also leads to poor performance.\n",
    "\n",
    "it seems that explic- itly saying “intend to offend\" is useful in surfacing out the LLMs’ underlying self-diagnosing abilities\n",
    "\n",
    "(Wang & Chang 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicSpeech_temp = \"\"\"Best Practice: Toxic Speech Detection\n",
    "Your task is to check the comments section for toxic speech.\n",
    "If you detect toxic speech, return the comment, the author, the datetime, and give a recommendation how to updated the comment.\"\"\"\n",
    "\n",
    "toxicSpeech_prompt = PromptTemplate(template= toxicSpeech_temp, input_variables= [])\n",
    "\n",
    "toxicSpeech_prompt.save(\"prompts/toxicSpeech/toxicSpeechPrompt_V1.5.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output format prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicSpeech_format_temp = \"\"\"### Instruction ###\n",
    "You receive a list of comments from a revised ticket from an issue tracker.\n",
    "Return the given Data for each entry in the following format in JSON:\n",
    "\"comment\": \"<content of the original comment>\",\n",
    "\"author\": \"<name of the original comment>\",\n",
    "\"datetime\": \"<datetime of the original comment>\",\n",
    "\"recommendation\": \"<only the revised string of the new comment>\"\n",
    "\"reason\": \"<reason for the recommendation>\"\n",
    "If the list is empty return \"no toxic speech detected\".\n",
    "\n",
    "### Context ###\n",
    "Data: {revised_ticket} \"\"\"\n",
    "\n",
    "toxicSpeech_format_prompt = PromptTemplate(template= toxicSpeech_format_temp, input_variables= [\"revised_ticket\"])\n",
    "\n",
    "toxicSpeech_format_prompt.save(\"prompts/toxicSpeech/toxicSpeechFormatPrompt_V1.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internationalization Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprache variable machen\n",
    "internationalization_temp = \"\"\"Best Practice: Internationalization\n",
    "Bug reports not written in English are often closed immediately or ignored by developers.\n",
    "Your task is to check if the \"Summary\", \"Description\", or \"Comments\" fields of the ticket are written in English.\n",
    "If some fields of the ticket are not written in English, provide a translation.\n",
    "Return only the revised ticket and nothing else.\"\"\"\n",
    "\n",
    "internationalization_prompt = PromptTemplate(template= internationalization_temp, input_variables= [])\n",
    "\n",
    "internationalization_prompt.save(\"prompts/internationalization/internationalizationPrompt_V1.5.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output format prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internationalization_format_temp = \"\"\"### Instruction ###\n",
    "You receive a revised ticket from an issue tracker in JSON format.\n",
    "Return the given Data in the following format in JSON:\n",
    "\"<field>\": \"<content of the field>\"\n",
    "\n",
    "### Context ###\n",
    "Data: {revised_ticket}\"\"\"\n",
    "\n",
    "internationalization_format_prompt = PromptTemplate(template= internationalization_format_temp, input_variables= [\"revised_ticket\"])\n",
    "\n",
    "internationalization_format_prompt.save(\"prompts/internationalization/internationalizationFormatPrompt_V1.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Report Structure Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe more of this structure:\n",
    "- https://bugzilla.mozilla.org/page.cgi?id=bug-writing.html\n",
    "- https://bugs.eclipse.org/bugs/page.cgi?id=bug-writing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"\"\"{{'Summary':'Sourcetree crashes',\n",
    "'Description':'Source tree crashes everytime i open , I have uninstalled and installed many times',\n",
    "'VersionsAffected':'3.4.4',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Sourcetree for Windows',\n",
    "'Components':'Git',\n",
    "'CreatedDate':'2021-09-13T05:48:08.000+0000',\n",
    "'ResolvedDate':'2021-11-18T15:12:59.000+0000',\n",
    "'Status':'Closed',\n",
    "'Priority':'Low',\n",
    "'Creator':'John Doe',\n",
    "'Reporter':'John Doe',\n",
    "'Resolution':'Cannot Reproduce',\n",
    "'IssueLinks':null,\n",
    "'Labels':null,\n",
    "'VersionsFixed':null,\n",
    "'Assignee':null,\n",
    "'TimeSpent':null,\n",
    "'Comments':[\n",
    "{{\n",
    "'Author':'Max Mustermann',\n",
    "'Created':'2021-11-18 15:12:59.861000+00:00',\n",
    "'Comment':'Issue was fixed in latest Sourcetree versions. Please use Sourcetree 3.4.5 > '\n",
    "}}\n",
    "]\n",
    "}}\"\"\",\n",
    "        \"output\": \"\"\"\n",
    "1. Overview\n",
    "Source tree crashes everytime i open , I have uninstalled and installed many times\n",
    "\n",
    "2. Steps to reproduce\n",
    "!not provided\n",
    "\n",
    "3. Actual result\n",
    "Source tree crashes\n",
    "\n",
    "4. Expected result\n",
    "Source tree does not crash\n",
    "\n",
    "5. Stack Traces\n",
    "!not provided\n",
    "\n",
    "6. Build date and hardware\n",
    "!not provided\n",
    "\n",
    "7. Additional information\n",
    "!not provided\n",
    "\"\"\" \n",
    "    },\n",
    "    {\n",
    "\"input\": \"\"\"\n",
    "{{\n",
    "'Summary':'Opening and closing Sourcetree causes Pageant to crash\\/close',\n",
    "'Description':'I have installed putty and pageant outside of Sourcetree, and I have Pageant startup during OS boot so my key-file is always ready.\\r\\n\\r\\nDidn't quite notice it at first, so not sure which version it started at, but Sourcetree now causes Pageant to crash\\/close when it opens or closes, causing e.g. git commands and such from command line to suddenly start to failing for no apparent reason.\\r\\n\\r\\nWhenever I open or close Sourcetree now, I have to reopen Pageant and reload my key, including entering a long passkey. Super annoying. Sourcetree shouldn't close or cause any other applications to crash when it opens or when it closes.\\r\\n\\r\\nIt happens on all 3 computers of mine. All running latest Windows, latest Pageant, and latest Sourcetree.',\n",
    "'VersionsAffected':'3.4.4',\n",
    "'IssueType':'Bug',\n",
    "'Project':'Sourcetree for Windows',\n",
    "'Components':'General',\n",
    "'CreatedDate':'2021-04-26T08:26:07.000+0000',\n",
    "'ResolvedDate':'2021-04-27T06:38:20.000+0000',\n",
    "'Status':'Closed',\n",
    "'Priority':'Low',\n",
    "'Creator':'Jane Doe',\n",
    "'Reporter':'Jane Doe',\n",
    "'Resolution':'Duplicate',\n",
    "'IssueLinks':null,\n",
    "'Labels':'verified',\n",
    "'VersionsFixed':null,\n",
    "'Assignee':null,\n",
    "'TimeSpent':null,\n",
    "'Comments':[\n",
    "{{\n",
    "'Author':'Jane Doe',\n",
    "'Created':'2021-04-26 08:41:02.391000+00:00',\n",
    "'Comment':'I have tried to disable the \\\"Automatically start SSH agent when Sourcetree opens\\\" option, as I thought maybe that was what was messing with things, but that didn't change anything. Pageant still disappears from my systray when Sourcetree opens or closes.'\n",
    "}},\n",
    "{{\n",
    "'Author':'Jane Doe',\n",
    "'Created':'2021-04-26 08:42:41.095000+00:00',\n",
    "'Comment':'Just noticed Sourcetree even causes Pageant to crash\\/close when I close the Options dialog... \\ud83d\\ude44'\n",
    "}},\n",
    "{{\n",
    "'Author':'Jonathan Smith',\n",
    "'Created':'2021-04-26 10:07:20.880000+00:00',\n",
    "'Comment':'Known issue, duplicate. Please use ticket\\u00a0SRCTREEWIN-13475\\u00a0for suggestions and tracking updates.'\n",
    "}}\n",
    "]\n",
    "}}\"\"\",\n",
    "\"output\": \"\"\"\n",
    "1. Overview\n",
    "I have installed putty and pageant outside of Sourcetree, and I have Pageant startup during OS boot so my key-file is always ready. Didn't quite notice it at first, but Sourcetree now causes Pageant to crash/close when it opens or closes, causing e.g. git commands and such from command line to suddenly start to failing for no apparent reason. Whenever I open or close Sourcetree now, I have to reopen Pageant and reload my key, including entering a long passkey. Super annoying. It happens on all 3 computers of mine.             \n",
    "\n",
    "2. Steps to reproduce\n",
    "- Install putty and pageant outside of Sourcetree\n",
    "- Set Pageant to startup during OS boot\n",
    "- pen or close Sourcetree\n",
    "\n",
    "3. Actual result\n",
    "Sourcetree causes Pageant to crash\\/close when it opens or closes.\n",
    "\n",
    "4. Expected result\n",
    "Sourcetree should not close or cause any other applications to crash when it opens or when it closes.\n",
    "\n",
    "5. Stack Traces\n",
    "!not provided\n",
    "\n",
    "6. Build date and hardware\n",
    "All running latest Windows, latest Pageant, and latest Sourcetree.\n",
    "Not sure which version it started.\n",
    "\n",
    "7. Additional information\n",
    "- I have tried to disable the \"Automatically start SSH agent when Sourcetree opens\" option, as I thought maybe that was what was messing with things, but that didn't change anything. Pageant still disappears from my systray when Sourcetree opens or closes.\n",
    "- Just noticed Sourcetree even causes Pageant to crash/close when I close the Options dialog.\n",
    "\"\"\" \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"], \n",
    "    template=\"\"\"### Context ###\n",
    "A bug report is a document that describes an issue with a product or service and why it needs fixing.\n",
    "The description field is significant for the bug report, as it describes the issue in detail.\n",
    "The description should contain the following structure:\n",
    "1. Overview: This is more detailed than the summary field of the bug report, with a description of the context when the error occurred.\n",
    "2. Steps to reproduce: A list of steps to reproduce the error.\n",
    "3. Actual result: The result that is currently produced.\n",
    "4. Expected result: The result that is expected.\n",
    "5. Stack Traces: A list of relevant stack traces for the bug report.\n",
    "6. Build date and hardware: The build date and hardware, when and where the bug occurred.\n",
    "7. Additional information: Additional information relevant to the bug report. That can be screenshots, videos, or other files.\n",
    "\n",
    "### Instruction ###\n",
    "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
    "Rearrange the description field of the bug report to match the structure described above.\n",
    "Your outputs should correspond to those a Software Enginee would regarding the bug report.\n",
    "If some information is missing, give suggestions and add them to the description field, if possible.\n",
    "Return the new description field and nothing else.\n",
    "\n",
    "The bug report is provided in JSON format.\n",
    "Bug Report: {input} \\n {output}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More space between the steps\n",
    "\n",
    "Needs a cleaner look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugReportStructure_fs_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix= \"\"\"### Context ###\n",
    "A bug report is a document that describes an issue with a product or service and why it needs fixing.\n",
    "The description field is significant for the bug report, as it describes the issue in detail.\n",
    "The description should contain the following structure:\n",
    "1. Overview: This is more detailed than the summary field of the bug report, with a description of the context when the error occurred.\n",
    "2. Steps to reproduce: A list of steps to reproduce the error.\n",
    "3. Actual result: The result that is currently produced.\n",
    "4. Expected result: The result that is expected.\n",
    "5. Stack Traces: A list of relevant stack traces for the bug report.\n",
    "6. Build date and hardware: The build date and hardware, when and where the bug occurred.\n",
    "7. Additional information: Additional information relevant to the bug report. That can be screenshots, videos, or other files.\n",
    "\n",
    "### Instruction ###\n",
    "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
    "Rearrange the description field of the bug report to match the structure described above.\n",
    "Your outputs should correspond to those a Software Enginee would regarding the bug report.\n",
    "Return the new description field and nothing else.\n",
    "\n",
    "The bug report is provided in JSON format.\n",
    "Bug Report: {bug_report}\"\"\",\n",
    "    input_variables=[\"bug_report\"]\n",
    ")\n",
    "\n",
    "bugReportStructure_fs_prompt.save(\"prompts/bugReportStructure/bugReportStructurePrompt_V2.3.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-shot (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugReportStructure_temp = \"\"\"### Context ###\n",
    "A bug report is a document that describes an issue with a product or service and why it needs fixing.\n",
    "The description field is significant for the bug report, as it describes the issue in detail.\n",
    "The description should contain the following structure:\n",
    "1. Overview: This is more detailed than the summary field of the bug report, with a description of the context when the error occurred.\n",
    "2. Steps to reproduce: A list of steps to reproduce the error.\n",
    "3. Actual result: The result that is currently produced.\n",
    "4. Expected result: The result that is expected.\n",
    "5. Stack Traces: A list of relevant stack traces for the bug report.\n",
    "6. Build date and hardware: The build date and hardware, when and where the bug occurred.\n",
    "7. Additional information: Additional information relevant to the bug report. That can be screenshots, videos, or other files.\n",
    "\n",
    "### Instruction ###\n",
    "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
    "Rearrange the description field of the bug report to match the structure described above.\n",
    "Your outputs should correspond to those a Software Enginee would regarding the bug report.\n",
    "If some information is missing, give suggestions and add them to the description field, if possible.\n",
    "Return the new description field and nothing else.\n",
    "\n",
    "The bug report is provided in JSON format.\n",
    "Bug Report: {bug_report}\n",
    "\"\"\"\n",
    "\n",
    "bugReportStructure_prompt = PromptTemplate(\n",
    "    template=bugReportStructure_temp, \n",
    "    input_variables=[\"bug_report\"])\n",
    "\n",
    "bugReportStructure_prompt.save(\"prompts/bugReportStructure/bugReportStructurePrompt_V1.2.0.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
