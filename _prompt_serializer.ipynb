{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_temp = \"\"\"### Instruction ###\n",
    "Act as a professional {role} working with issue trackers like Jira or Azure DevOps.\n",
    "Working with these issue trackers, you must consider multiple text-based best practices to increase understandability and reduce time.\n",
    "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
    "The best practice to check is: \n",
    "{best_practice}\n",
    "\n",
    "### Context ###\n",
    "A ticket consists of multiple fields. You are provided with the fields and a short description for each field.\n",
    "Assignee: The person responsible to resolve the issue.\n",
    "Comments: Community discussion on the issue, including author, timestamp, and content.\n",
    "Components: Project components to which the issue belongs.\n",
    "CreatedDate: The time and date the issue was created.\n",
    "Creator: The person who created the issue.\n",
    "Description: A detailed description of the issue.\n",
    "IssueLinks: A list of links to related issues.\n",
    "IssueType: The issue's purpose within the organization.\n",
    "Labels: Labels to which this issue relates.\n",
    "Priority: The issue importance in relation to other issues.\n",
    "Project: The parent project to which the issue belongs.\n",
    "Reporter: The person who found/reported the issue.\n",
    "Resolution: A record of the issue's resolution, once resolved or closed.\n",
    "ResolvedDate: The time and date the issue was resolved.\n",
    "Status: The stage the issue is currently at in its lifecycle.\n",
    "Summary: A brief one-line summary of the issue.\n",
    "TimeSpent: Amount of time spent working on the issue.\n",
    "VersionsAffected: The versions of the project affected by the issue.\n",
    "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
    "\n",
    "You will receive this ticket from an issue tracker in JSON format.\n",
    "Ticket: {ticket}\n",
    "\"\"\"\n",
    "init_prompt = PromptTemplate(template= init_temp, input_variables= [\"role\", \"best_practice\", \"ticket\"])\n",
    "\n",
    "init_prompt.save(\"prompts/init/initPrompt_V1.1.2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_temp =\"\"\"Best Practice: Update Missing/Outdated Fields\n",
    "Get contextual knowledge about the ticket through the 'Summary', 'Description', and 'Comments' fields.\n",
    "Identify any missing or outdated fields and form recommendations for updates.\n",
    "Return a list with the changes you made with the addition of recommendations and nothing else.\n",
    "Each list item should be an object in the following format:\n",
    "\"field\": \"<name of the missing or outdated field>\",\n",
    "\"recommendation\": \"<recommendation on how to update the field and why>\"\n",
    "\n",
    "If you do not have to update fields, return \"Everything is up to date\".\"\"\"\n",
    "\n",
    "update_prompt = PromptTemplate(template= update_temp, input_variables= [])\n",
    "update_prompt.save(\"prompts/update/updatePrompt_V1.12.2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_temp = \"\"\"Best Practice: Summary Length\n",
    "Your Task is to check if the ticket summary has exactly between {min} and {max} characters.\n",
    "If the number of characters is exactly in this range, return the original summary.\n",
    "Otherwise, recommend a new summary based on the information of the description field for the ticket.\n",
    "Please return only the summary and nothing else.\"\"\"\n",
    "\n",
    "sumLen_prompt = PromptTemplate(template= sumLen_temp, input_variables= [\"min\", \"max\"])\n",
    "\n",
    "sumLen_prompt.save(\"prompts/summary/summaryLengthPrompt_V2.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Length Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descLen_temp = \"\"\"Best Practice: Description Length\n",
    "Your Task is to check if the ticket description is between {min} and {max} words.\n",
    "Ignore source code snippets or images in the description.\n",
    "If the word count is in this range, return the original description.\n",
    "Otherwise, recommend a new description for the ticket.\n",
    "Please return only the description and nothing else.\"\"\"\n",
    "\n",
    "descLen_prompt = PromptTemplate(template= descLen_temp, input_variables= [\"min\", \"max\"])\n",
    "\n",
    "descLen_prompt.save(\"prompts/description/descriptionLengthPrompt_V1.0.2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic Speech Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicSpeech_temp = \"\"\"Best Practice: Toxic Speech Detection\n",
    "Your task is to check the comments section for toxic speech.\n",
    "If you detect toxic speech, return a list with the comment, the author, and the datetime.\n",
    "Each list item should be an object in the following format:\n",
    "\"comment\": \"<content of the original comment>\",\n",
    "\"author\": \"<name of the original comment>\",\n",
    "\"datetime\": \"<datetime of the original comment>\",\n",
    "\"recommendation\": \"<recommendation on how to update the comment and why>\"\n",
    "\n",
    "If you do not detect toxic speech, return \"no toxic speech detected\".\"\"\"\n",
    "\n",
    "toxicSpeech_prompt = PromptTemplate(template= toxicSpeech_temp, input_variables= [])\n",
    "\n",
    "toxicSpeech_prompt.save(\"prompts/toxicSpeech/toxicSpeechPrompt_V1.2.4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internationalization Prompt (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "internationalization_temp = \"\"\"Best Practice: Internationalization\n",
    "Bug reports not written in English are often closed immediately or ignored by developers.\n",
    "Your task is to check if the ticket is written in English.\n",
    "If some fields of the ticket are not written in English, provide a translation.\n",
    "Return only the translated fields in the following structure and nothing else.\n",
    "\"<field>\": \"<English translation of the original field>\"\n",
    "\"\"\"\n",
    "\n",
    "internationalization_prompt = PromptTemplate(template= internationalization_temp, input_variables= [])\n",
    "\n",
    "internationalization_prompt.save(\"prompts/internationalization/internationalizationPrompt_V1.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug Report Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugReportStructure_temp = \"\"\"### Context ###\n",
    "A bug report is a document that describes an issue with a product or service and why it needs fixing.\n",
    "The description field is significant for the bug report, as it describes the issue in detail.\n",
    "The description should contain the following structure:\n",
    "1. Overview: This is more detailed than the summary field of the bug report, with a description of the context when the error occurred.\n",
    "2. Steps to reproduce: A list of steps to reproduce the error.\n",
    "3. Actual result: The result that is currently produced.\n",
    "4. Expected result: The result that is expected.\n",
    "5. Stack Traces: A list of relevant stack traces for the bug report.\n",
    "6. Build date and hardware: The build date and hardware, when and where the bug occurred.\n",
    "7. Additional information: Additional information relevant to the bug report. That can be screenshots, videos, or other files.\n",
    "\n",
    "### Instruction ###\n",
    "Act as a professional {role} working with issue trackers like Jira or Azure DevOps.\n",
    "Rearrange the description field of the bug report to match the structure described above.\n",
    "If some information is missing, give suggestions and add them to the description field, if possible.\n",
    "Return the new description field and nothing else.\n",
    "\n",
    "The bug report is provided in JSON format.\n",
    "Bug Report: {bug_Report}\n",
    "\"\"\"\n",
    "\n",
    "bugReportStructure_prompt = PromptTemplate(template=bugReportStructure_temp, input_variables=[\"role\", \"bug_Report\"])\n",
    "\n",
    "bugReportStructure_prompt.save(\"prompts/bugReportStructure/bugReportStructurePrompt_V1.0.1.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
