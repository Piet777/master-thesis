{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(output, prompt_type, model, init, best_practice):\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    result = {}\n",
    "    result['model'] = model\n",
    "    result['creation_timestamp'] = date + ' ' + time\n",
    "    result['prompts'] = {\n",
    "        'init_uri': init,\n",
    "        'best_practice_uri': best_practice}\n",
    "    result['output'] = output\n",
    "\n",
    "    with open('results/'+prompt_type+'/output_'+date+'_'+time+'.json', 'w') as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4'\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    api_key=open('api.txt', 'r').read(),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row.json') as f:\n",
    "    json_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'summaryLengthPrompt_V1.0.2.json'\n",
    "bestPractice_prompt = load_prompt('prompts/summary/'+bestPractice_prompt_name).format(min= 6, max= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### Instruction ###\n",
      "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
      "Working with these issue trackers, you must consider multiple text-based best practices to increase understandability and reduce time.\n",
      "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
      "The best practice to check is: \n",
      "\n",
      "Best Practice: Summary Length\n",
      "Your Task is to check if the ticket summary is between 6 and 10 words.\n",
      "If the word count is in this range, return the original summary.\n",
      "Otherwise, recommend a new summary for the ticket.\n",
      "Please return only the summary string and nothing else.\n",
      "\n",
      "\n",
      "### Context ###\n",
      "A ticket consists of multiple fields. You are provided with the fields and a short description for each field.\n",
      "Assignee: The person responsible to resolve the issue.\n",
      "Comments: Community discussion on the issue, including author, timestamp and content.\n",
      "Components: Project components to which the issue belongs.\n",
      "CreatedDate: The time and date the issue was created.\n",
      "Creator: The person who created the issue.\n",
      "Description: A detailed description of the issue.\n",
      "IssueLinks: A list of links to related issues.\n",
      "IssueType: The issue's purpose within the organization.\n",
      "Labels: Labels to which this issue relates.\n",
      "Priority: The issue importance in relation to other issues.\n",
      "Project: The parent project to which the issue belongs.\n",
      "Reporter: The person who found/reported the issue.\n",
      "Resolution: A record of the issue's resolution, once resolved or closed.\n",
      "ResolvedDate: The time and date the issue was resolved.\n",
      "Status: The stage the issue is currently at in its lifecycle.\n",
      "Summary: A brief one-line summary of the issue.\n",
      "TimeSpent: Amount of time spent working on the issue.\n",
      "VersionsAffected: The versions of the project affected by the issue.\n",
      "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
      "\n",
      "You will receive this ticket from an issue tracker in JSON format.\n",
      "Ticket: {'Summary': 'Sourcetree crashes', 'Description': 'Source tree crashes everytime i open , I have uninstalled and installed many times', 'VersionsAffected': '3.4.4', 'IssueType': 'Bug', 'Project': 'Sourcetree for Windows', 'Components': 'Git', 'CreatedDate': '2021-09-13T05:48:08.000+0000', 'ResolvedDate': '2021-11-18T15:12:59.000+0000', 'Status': 'Closed', 'Priority': 'Low', 'Creator': 'Shefali Bhandary', 'Reporter': 'Shefali Bhandary', 'Resolution': 'Cannot Reproduce', 'IssueLinks': None, 'Labels': None, 'VersionsFixed': None, 'Assignee': None, 'TimeSpent': None, 'Comments': [{'Author': 'Vipin Yadav', 'Created': '2021-09-13 06:12:40.315000+00:00', 'Comment': 'Please try to install latest release of sourcetree 3.4.6 and let us know if you are still facing same issue.'}, {'Author': 'Shefali Bhandary', 'Created': '2021-09-13 06:56:53.753000+00:00', 'Comment': 'In our software portal on 3.2.6 is available'}, {'Author': 'Vipin Yadav', 'Created': '2021-09-13 07:15:30.197000+00:00', 'Comment': '3.2.6 is very old (was released in July 2019). Latest is 3.4.6 so try to use the current release 3.4.6'}, {'Author': 'Oleksandr Naumenko', 'Created': '2021-11-18 15:12:59.861000+00:00', 'Comment': 'Issue was fixed in latest Sourcetree versions. Please use Sourcetree 3.4.5 > '}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = init_prompt | model | StrOutputParser()\n",
    "print(init_prompt.format(role=\"Software Engineer\", best_practice=bestPractice_prompt, ticket=json_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sourcetree crashes upon opening repeatedly\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'summary', model_name, init_prompt_name, bestPractice_prompt_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe usefull for later\n",
    "# def run(model_name, init_prompt_name, sumLen_prompt_name):\n",
    "#     model = ChatOpenAI(\n",
    "#         model=model_name,\n",
    "#         api_key=open('api.txt', 'r').read(),\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     with open('./data/json/last_row.json') as f:\n",
    "#         json_sample = json.load(f)\n",
    "\n",
    "#     init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "#     sumLen_prompt = load_prompt('prompts/summary/'+sumLen_prompt_name).format(min= 6, max= 10)\n",
    "    \n",
    "#     chain = init_prompt | model | StrOutputParser()\n",
    "\n",
    "#     output = chain.invoke({\"best_practice\": sumLen_prompt,\"ticket\": json_sample})\n",
    "\n",
    "#     save_result(output, 'summary', model_name, init_prompt_name, sumLen_prompt_name)  \n",
    "\n",
    "# run('gpt-4', 'initPrompt_V1.0.0.json', 'summaryLengthPrompt_V1.0.1.json')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'descriptionLengthPrompt_V1.0.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/description/'+bestPractice_prompt_name).format(min= 29, max= 111)\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Source tree crashes every time I open it. I have uninstalled and reinstalled the software multiple times but the issue persists. This issue is occurring on version 3.4.4. I have tried to update to the latest version but our software portal only has version 3.2.6 available. Any assistance in resolving this issue would be greatly appreciated.'\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'description', model_name, init_prompt_name, bestPractice_prompt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'updatePrompt_V1.2.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/update/'+bestPractice_prompt_name).format()\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Changes Made:\\n1. Updated 'Assignee' field from None to 'Shefali Bhandary' as she was the one who reported the issue and also participated in the comments to resolve it.\\n2. Updated 'TimeSpent' field from None to '2 months 5 days' calculated from 'CreatedDate' and 'ResolvedDate'.\\n3. Updated 'VersionsFixed' field from None to '3.4.5' based on the last comment by 'Oleksandr Naumenko'.\\n4. Added 'Software Update' to 'Labels' field as the issue was resolved by updating the software.\\n\\nRecommendations:\\n1. Always assign an issue to a team member to ensure accountability.\\n2. Keep track of the time spent on resolving the issue for better project management.\\n3. Update the 'VersionsFixed' field once the issue is resolved in a particular version.\\n4. Use 'Labels' field to categorize the issue for easy tracking and reporting.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'update', model_name, init_prompt_name, bestPractice_prompt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'toxicSpeechPrompt_V1.0.1.json'\n",
    "bestPractice_prompt = load_prompt('prompts/toxicSpeech/'+bestPractice_prompt_name).format()\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After reviewing the comments in the ticket, it is clear that all the comments are professional and related to the issue at hand. There is no toxic speech detected in the comments. The authors of the comments are 'Vipin Yadav', 'Shefali Bhandary', and 'Oleksandr Naumenko'. All of them have maintained a professional tone while discussing the issue. \\n\\nTherefore, 'No toxic speech detected.'\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Content Moderator\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'toxicSpeech', model_name, init_prompt_name, bestPractice_prompt_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
