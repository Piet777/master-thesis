{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(output, prompt_type, model, init, best_practice, output_parser):\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    result = {}\n",
    "    result['model'] = model\n",
    "    result['creation_timestamp'] = date + ' ' + time\n",
    "    result['prompts'] = {\n",
    "        'init_uri': init,\n",
    "        'best_practice_uri': best_practice}\n",
    "    result['output_parser'] = output_parser \n",
    "    result['output'] = output\n",
    "\n",
    "    with open('results/'+prompt_type+'/output_'+date+'_'+time+'.json', 'w') as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringToJSON(string):\n",
    "    if string[0] != '{':\n",
    "        string = \"{\"+string+\"}\"\n",
    "\n",
    "    json_object = json.loads(string)\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4'\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    api_key=open('api.txt', 'r').read(),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row.json') as f:\n",
    "    json_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# class ListItem(BaseModel):\n",
    "#     \"\"\"Item of a list\"\"\"\n",
    "\n",
    "#     id: int = Field(description=\"The item identifier\")\n",
    "#     content: str = Field(description=\"The item content\")\n",
    "\n",
    "#     @validator(\"id\")\n",
    "#     def validate_id(cls, field):\n",
    "#         if not field:\n",
    "#             raise ValueError(\"Item ID cannot be empty!\")\n",
    "#         return field\n",
    "    \n",
    "#     @validator(\"content\")\n",
    "#     def validate_content(cls, field):\n",
    "#         if not field:\n",
    "#             raise ValueError(\"Item content cannot be empty!\")\n",
    "#         return field\n",
    "    \n",
    "# parser = PydanticOutputParser(pydantic_object=ListItem)\n",
    "# ...\n",
    "# bestPractice_prompt = load_prompt('prompts/update/'+bestPractice_prompt_name).format(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'summaryLengthPrompt_V1.0.3.json'\n",
    "bestPractice_prompt = load_prompt('prompts/summary/'+bestPractice_prompt_name).format(min= 6, max= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### Instruction ###\n",
      "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
      "Working with these issue trackers, you must consider multiple text-based best practices to increase understandability and reduce time.\n",
      "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
      "The best practice to check is: \n",
      "\n",
      "Best Practice: Summary Length\n",
      "Your Task is to check if the ticket summary is between 6 and 10 words.\n",
      "If the word count is in this range, return the original summary.\n",
      "Otherwise, recommend a new summary for the ticket.\n",
      "Please return only the summary and nothing else.\n",
      "\n",
      "\n",
      "### Context ###\n",
      "A ticket consists of multiple fields. You are provided with the fields and a short description for each field.\n",
      "Assignee: The person responsible to resolve the issue.\n",
      "Comments: Community discussion on the issue, including author, timestamp and content.\n",
      "Components: Project components to which the issue belongs.\n",
      "CreatedDate: The time and date the issue was created.\n",
      "Creator: The person who created the issue.\n",
      "Description: A detailed description of the issue.\n",
      "IssueLinks: A list of links to related issues.\n",
      "IssueType: The issue's purpose within the organization.\n",
      "Labels: Labels to which this issue relates.\n",
      "Priority: The issue importance in relation to other issues.\n",
      "Project: The parent project to which the issue belongs.\n",
      "Reporter: The person who found/reported the issue.\n",
      "Resolution: A record of the issue's resolution, once resolved or closed.\n",
      "ResolvedDate: The time and date the issue was resolved.\n",
      "Status: The stage the issue is currently at in its lifecycle.\n",
      "Summary: A brief one-line summary of the issue.\n",
      "TimeSpent: Amount of time spent working on the issue.\n",
      "VersionsAffected: The versions of the project affected by the issue.\n",
      "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
      "\n",
      "You will receive this ticket from an issue tracker in JSON format.\n",
      "Ticket: {'Summary': 'Sourcetree crashes', 'Description': 'Source tree crashes everytime i open , I have uninstalled and installed many times', 'VersionsAffected': '3.4.4', 'IssueType': 'Bug', 'Project': 'Sourcetree for Windows', 'Components': 'Git', 'CreatedDate': '2021-09-13T05:48:08.000+0000', 'ResolvedDate': '2021-11-18T15:12:59.000+0000', 'Status': 'Closed', 'Priority': 'Low', 'Creator': 'Shefali Bhandary', 'Reporter': 'Shefali Bhandary', 'Resolution': 'Cannot Reproduce', 'IssueLinks': None, 'Labels': None, 'VersionsFixed': None, 'Assignee': None, 'TimeSpent': None, 'Comments': [{'Author': 'Vipin Yadav', 'Created': '2021-09-13 06:12:40.315000+00:00', 'Comment': 'Please try to install latest release of sourcetree 3.4.6 and let us know if you are still facing same issue.'}, {'Author': 'Shefali Bhandary', 'Created': '2021-09-13 06:56:53.753000+00:00', 'Comment': 'In our software portal on 3.2.6 is available'}, {'Author': 'Vipin Yadav', 'Created': '2021-09-13 07:15:30.197000+00:00', 'Comment': '3.2.6 is very old (was released in July 2019). Latest is 3.4.6 so try to use the current release 3.4.6'}, {'Author': 'Oleksandr Naumenko', 'Created': '2021-11-18 15:12:59.861000+00:00', 'Comment': 'Issue was fixed in latest Sourcetree versions. Please use Sourcetree 3.4.5 > '}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = init_prompt | model | StrOutputParser()\n",
    "print(init_prompt.format(role=\"Software Engineer\", best_practice=bestPractice_prompt, ticket=json_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Sourcetree crashes upon opening repeatedly'\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'summary', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe usefull for later\n",
    "# def run(model_name, init_prompt_name, sumLen_prompt_name):\n",
    "#     model = ChatOpenAI(\n",
    "#         model=model_name,\n",
    "#         api_key=open('api.txt', 'r').read(),\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     with open('./data/json/last_row.json') as f:\n",
    "#         json_sample = json.load(f)\n",
    "\n",
    "#     init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "#     sumLen_prompt = load_prompt('prompts/summary/'+sumLen_prompt_name).format(min= 6, max= 10)\n",
    "    \n",
    "#     chain = init_prompt | model | StrOutputParser()\n",
    "\n",
    "#     output = chain.invoke({\"best_practice\": sumLen_prompt,\"ticket\": json_sample})\n",
    "\n",
    "#     save_result(output, 'summary', model_name, init_prompt_name, sumLen_prompt_name)  \n",
    "\n",
    "# run('gpt-4', 'initPrompt_V1.0.0.json', 'summaryLengthPrompt_V1.0.1.json')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'descriptionLengthPrompt_V1.0.1.json'\n",
    "bestPractice_prompt = load_prompt('prompts/description/'+bestPractice_prompt_name).format(min= 29, max= 111)\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current description: \"Source tree crashes everytime i open , I have uninstalled and installed many times\"\\n\\nThis description is too short with only 12 words. A more detailed description is recommended for better understanding of the issue.\\n\\nRecommended description: \"I am experiencing an issue where Sourcetree crashes every time I attempt to open it. This has been a consistent problem, and I have tried to resolve it by uninstalling and reinstalling the software multiple times, but the issue persists. The version I am using is 3.4.4. This problem is hindering my work as I am unable to access my repositories. Any assistance in resolving this issue would be greatly appreciated.\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'description', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'updatePrompt_V1.11.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/update/'+bestPractice_prompt_name).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = StringToJSON(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output_json, 'update', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row_toxic.json') as f:\n",
    "    toxic_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.1.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'toxicSpeechPrompt_V1.2.1.json'\n",
    "bestPractice_prompt = load_prompt('prompts/toxicSpeech/'+bestPractice_prompt_name).format()\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"results\": [\\n    {\\n        \"comment\": \"Issue was fixed in latest Sourcetree versions you idiot. Use your brain and use Sourcetree 3.4.5 > \",\\n        \"author\": \"Oleksandr Naumenko\",\\n        \"datetime\": \"2021-11-18 15:12:59.861000+00:00\",\\n        \"recommendation\": \"The comment contains toxic speech. It is recommended to revise the comment to maintain a respectful and professional tone. For example, \\'The issue was fixed in the latest Sourcetree versions. Please consider using Sourcetree 3.4.5 or later.\\'\"\\n    }\\n]'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Content Moderator\", \"best_practice\":bestPractice_prompt, \"ticket\":toxic_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = StringToJSON(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output_json, 'toxicSpeech', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug Report Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugReportStrucutre_prompt_name = 'bugReportStructurePrompt_V1.0.0.json'\n",
    "bugReportStrucutre_prompt = load_prompt('prompts/bugReportStructure/'+bugReportStrucutre_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = bugReportStrucutre_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"bug_Report\":json_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output_json, 'update', model_name, '-', bugReportStrucutre_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
