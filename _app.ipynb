{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(output, prompt_type, model, init, best_practice):\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    result = {}\n",
    "    result['model'] = model\n",
    "    result['creation_timestamp'] = date + ' ' + time\n",
    "    result['prompts'] = {\n",
    "        'init_uri': init,\n",
    "        'best_practice_uri': best_practice}\n",
    "    result['output'] = output\n",
    "\n",
    "    with open('results/'+prompt_type+'/output_'+date+'_'+time+'.json', 'w') as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4'\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    api_key=open('api.txt', 'r').read(),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row.json') as f:\n",
    "    json_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for JSOn Pitput ? https://www.youtube.com/watch?v=4vjYkKnGmFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.0.0.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "sumLen_prompt_name = 'summaryLengthPrompt_V1.0.1.json'\n",
    "sumLen_prompt = load_prompt('prompts/summary/'+sumLen_prompt_name).format(min= 6, max= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### Instruction ###\n",
      "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
      "Working with these issue trackers, you have to consider multiple text-based best practices to increase understandability and reduce time.\n",
      "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
      "The best practice to ckeck is: \n",
      "\n",
      "Best Practice: Summary Length\n",
      "Your Task is to check if the summary of the ticket is between 6 to 10 words.\n",
      "If the word count is in this range return the original summary.\n",
      "Else, recommend a new summary for the ticket.\n",
      "Please return only the summary string and nothing else.\n",
      "\n",
      "\n",
      "### Context ###\n",
      "A ticket consist of multiple fields. You are provided with the fields and a short desciption for each field.\n",
      "Assignee: The person responsible to resolve the issue.\n",
      "Comments: Community discussion on the issue.\n",
      "Components: Project components to which the issue belongs.\n",
      "CreatedDate: The time and date the issue was created.\n",
      "Creator: The person who created the issue.\n",
      "Description: A detailed description of the issue.\n",
      "IssueLinks: A list of links to related issues.\n",
      "IssueType: The issue purpose within the organization.\n",
      "Labels: Labels to which this issue relates.\n",
      "Priority: The issue importance in relation to other issues.\n",
      "Project: The parent project to which the issue belongs.\n",
      "Reporter: The person who found/reported the issue.\n",
      "Resolution: A record of the issue's resolution, once resolved or closed.\n",
      "ResolvedDate: The time and date the issue was resolved.\n",
      "Status: The stage the issue is currently at in its lifecycle.\n",
      "Summary: A brief one-line summary of the issue.\n",
      "TimeSpent: Amount of time spent working on the issue.\n",
      "VersionsAffected: The versions of the project affected by the issue.\n",
      "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
      "\n",
      "You will receive this ticket from an issue tracker in json format.\n",
      "Ticket: {'Summary': 'Sourcetree crashes', 'Description': 'Source tree crashes everytime i open , I have uninstalled and installed many times', 'VersionsAffected': '3.4.4', 'IssueType': 'Bug', 'Project': 'Sourcetree for Windows', 'Components': 'Git', 'CreatedDate': '2021-09-13T05:48:08.000+0000', 'ResolvedDate': '2021-11-18T15:12:59.000+0000', 'Status': 'Closed', 'Priority': 'Low', 'Creator': 'Shefali Bhandary', 'Reporter': 'Shefali Bhandary', 'Comments': 'Issue was fixed in latest Sourcetree versions. Please use Sourcetree 3.4.5 > ', 'Resolution': 'Cannot Reproduce', 'IssueLinks': None, 'Labels': None, 'VersionsFixed': None, 'Assignee': None, 'TimeSpent': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = init_prompt | model | StrOutputParser()\n",
    "print(init_prompt.format(best_practice= sumLen_prompt, ticket=json_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Sourcetree crashes on opening'\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"best_practice\": sumLen_prompt,\"ticket\": json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'summary', model_name, init_prompt_name, sumLen_prompt_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe usefull for later\n",
    "# def run(model_name, init_prompt_name, sumLen_prompt_name):\n",
    "#     model = ChatOpenAI(\n",
    "#         model=model_name,\n",
    "#         api_key=open('api.txt', 'r').read(),\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     with open('./data/json/last_row.json') as f:\n",
    "#         json_sample = json.load(f)\n",
    "\n",
    "#     init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "#     sumLen_prompt = load_prompt('prompts/summary/'+sumLen_prompt_name).format(min= 6, max= 10)\n",
    "    \n",
    "#     chain = init_prompt | model | StrOutputParser()\n",
    "\n",
    "#     output = chain.invoke({\"best_practice\": sumLen_prompt,\"ticket\": json_sample})\n",
    "\n",
    "#     save_result(output, 'summary', model_name, init_prompt_name, sumLen_prompt_name)  \n",
    "\n",
    "# run('gpt-4', 'initPrompt_V1.0.0.json', 'summaryLengthPrompt_V1.0.1.json')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
