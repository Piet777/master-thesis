{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(output, prompt_type, model, init, best_practice, format_prompt, output_parser):\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    result = {}\n",
    "    result['model'] = model\n",
    "    result['creation_timestamp'] = date + ' ' + time\n",
    "    result['prompts'] = {\n",
    "        'init_uri': init,\n",
    "        'best_practice_uri': best_practice,\n",
    "        'formatter_uri': format_prompt}\n",
    "    result['output_parser'] = output_parser \n",
    "    result['output'] = output\n",
    "\n",
    "    with open('results/'+prompt_type+'/output_'+date+'_'+time+'.json', 'w') as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringToJSON(string):\n",
    "    result = string\n",
    "\n",
    "    try:\n",
    "        if ((string[0] != \"{\") and (string[0] != \"[\")):\n",
    "            string = \"{\"+string+\"}\"\n",
    "\n",
    "        result = json.loads(string)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"JSON formatting went wrong. The result returns as a string.\")\n",
    "        \n",
    "    finally:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4'\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    api_key=open('api.txt', 'r').read(),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = \"suggestion_sample.json\"\n",
    "with open('./data/json/last_row/'+sample_name) as f:\n",
    "    json_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.2.0.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'summaryLengthPrompt_V2.3.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/summary/'+bestPractice_prompt_name).format(min=39, max=70)\n",
    "\n",
    "format_prompt_name = 'summaryLengthFormatPrompt_V1.0.0.json'\n",
    "format_prompt = load_prompt('prompts/summary/'+format_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = init_prompt | model | StrOutputParser()\n",
    "chain2 = (\n",
    "    {\"revised_ticket\": chain1}\n",
    "    | format_prompt\n",
    "    | model\n",
    "    | JsonOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_old': 'Project Summaries',\n",
       " 'summary_new': 'Single page display of project components and their issue status'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = await chain2.ainvoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be between 39 and 70\n",
    "len('Single page display of project components and their issue status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'summary', model_name, init_prompt_name, bestPractice_prompt_name, format_prompt_name, 'JsonOutputParser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe usefull for later\n",
    "# def run(model_name, init_prompt_name, sumLen_prompt_name):\n",
    "#     model = ChatOpenAI(\n",
    "#         model=model_name,\n",
    "#         api_key=open('api.txt', 'r').read(),\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     with open('./data/json/last_row.json') as f:\n",
    "#         json_sample = json.load(f)\n",
    "\n",
    "#     init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "#     sumLen_prompt = load_prompt('prompts/summary/'+sumLen_prompt_name).format(min= 6, max= 10)\n",
    "    \n",
    "#     chain = init_prompt | model | StrOutputParser()\n",
    "\n",
    "#     output = chain.invoke({\"best_practice\": sumLen_prompt,\"ticket\": json_sample})\n",
    "\n",
    "#     save_result(output, 'summary', model_name, init_prompt_name, sumLen_prompt_name)  \n",
    "\n",
    "# run('gpt-4', 'initPrompt_V1.0.0.json', 'summaryLengthPrompt_V1.0.1.json')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Length (maybe not usefull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.2.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'descriptionLengthPrompt_V2.7.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/description/'+bestPractice_prompt_name).format(min= 210, max= 850)\n",
    "\n",
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The description of the ticket is: \"A single page displaying all the different components for a project, and the status of different issues for the component. Could work with either open bugs per component, or planned features per component. (For all versions or for a specific version) See http://www7b.software.ibm.com/webapp/wsdd/wasServlet3?client=form10&SID=1013344492744 for how it might possibly look (I like the graphical status indicators)\". \\n\\nThis description is too short as per the best practice of having between 210 and 850 characters. \\n\\nRecommended description: \"The issue pertains to the development of a single page that displays all the different components of a project, along with the status of various issues related to each component. The page should be designed to work with either open bugs per component or planned features per component. This functionality should be applicable for all versions of the project or for a specific version, as required. For a visual representation of how this might look, refer to the following link: http://www7b.software.ibm.com/webapp/wsdd/wasServlet3?client=form10&SID=1013344492744. The graphical status indicators on this page are particularly appealing and could be incorporated into our design.\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'description', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.2.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'updatePrompt_V1.12.2.json'\n",
    "bestPractice_prompt = load_prompt('prompts/update/'+bestPractice_prompt_name).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = init_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":json_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = StringToJSON(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output_json, 'update', model_name, init_prompt_name, bestPractice_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row/last_row_toxic.json') as f:\n",
    "    toxic_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.1.2.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'toxicSpeechPrompt_V1.5.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/toxicSpeech/'+bestPractice_prompt_name).format()\n",
    "\n",
    "format_prompt_name = 'toxicSpeechFormatPrompt_V1.1.0.json'\n",
    "format_prompt = load_prompt('prompts/toxicSpeech/'+format_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = init_prompt | model | StrOutputParser()\n",
    "chain2 = (\n",
    "    {\"revised_ticket\": chain1}\n",
    "    | format_prompt\n",
    "    | model\n",
    "    | JsonOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment': 'Issue was fixed in latest Sourcetree versions you idiot. Use your brain and use Sourcetree 3.4.5 >',\n",
       " 'author': 'Oleksandr Naumenko',\n",
       " 'datetime': '2021-11-18 15:12:59.861000+00:00',\n",
       " 'recommendation': 'The issue has been resolved in the latest Sourcetree versions. I recommend using Sourcetree 3.4.5 or later.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = await chain2.ainvoke({\"role\":\"Content Moderator\", \"best_practice\":bestPractice_prompt, \"ticket\":toxic_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'toxicSpeech', model_name, init_prompt_name, bestPractice_prompt_name, format_prompt_name, 'JsonOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug Report Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugReportStrucutre_prompt_name = 'bugReportStructurePrompt_V2.1.0.json'\n",
    "bugReportStrucutre_prompt = load_prompt('prompts/bugReportStructure/'+bugReportStrucutre_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = bugReportStrucutre_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"bug_report\":json_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'bugReportStructure', model_name, '-', bugReportStrucutre_prompt_name, 'StrOutputParser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/last_row/last_row_german.json') as f:\n",
    "    german_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_name = 'initPrompt_V1.2.0.json'\n",
    "init_prompt = load_prompt('prompts/init/'+init_prompt_name)\n",
    "\n",
    "bestPractice_prompt_name = 'internationalizationPrompt_V2.1.0.json'\n",
    "bestPractice_prompt = load_prompt('prompts/internationalization/'+bestPractice_prompt_name).format()\n",
    "\n",
    "format_prompt_name = 'internationalizationFormatPrompt_V1.2.0.json'\n",
    "format_prompt = load_prompt('prompts/internationalization/'+format_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = init_prompt | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"revised_ticket\":chain1}\n",
    "    | format_prompt\n",
    "    | model\n",
    "    | JsonOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Summary': 'Sourcetree crashes',\n",
       " 'Description': 'The Sourcetree crashes every time I open it, I have uninstalled and installed several times',\n",
       " 'VersionsAffected': '3.4.4',\n",
       " 'IssueType': 'Bug',\n",
       " 'Project': 'Sourcetree for Windows',\n",
       " 'Components': 'Git',\n",
       " 'CreatedDate': '2021-09-13T05:48:08.000+0000',\n",
       " 'ResolvedDate': '2021-11-18T15:12:59.000+0000',\n",
       " 'Status': 'Closed',\n",
       " 'Priority': 'Low',\n",
       " 'Creator': 'Shefali Bhandary',\n",
       " 'Reporter': 'Shefali Bhandary',\n",
       " 'Resolution': 'Cannot Reproduce',\n",
       " 'IssueLinks': None,\n",
       " 'Labels': None,\n",
       " 'VersionsFixed': None,\n",
       " 'Assignee': None,\n",
       " 'TimeSpent': None,\n",
       " 'Comments': [{'Author': 'Vipin Yadav',\n",
       "   'Created': '2021-09-13 06:12:40.315000+00:00',\n",
       "   'Comment': 'Please try to install latest release of sourcetree 3.4.6 and let us know if you are still facing same issue.'},\n",
       "  {'Author': 'Shefali Bhandary',\n",
       "   'Created': '2021-09-13 06:56:53.753000+00:00',\n",
       "   'Comment': 'In our software portal on 3.2.6 is available'},\n",
       "  {'Author': 'Vipin Yadav',\n",
       "   'Created': '2021-09-13 07:15:30.197000+00:00',\n",
       "   'Comment': '3.2.6 is very old (was released in July 2019). Latest is 3.4.6 so try to use the current release 3.4.6'},\n",
       "  {'Author': 'Oleksandr Naumenko',\n",
       "   'Created': '2021-11-18 15:12:59.861000+00:00',\n",
       "   'Comment': 'Issue was fixed in latest Sourcetree versions. Please use Sourcetree 3.4.5 > '}]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = await chain2.ainvoke({\"role\":\"Software Engineer\", \"best_practice\":bestPractice_prompt, \"ticket\":german_sample})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(output, 'internationalization', model_name, init_prompt_name, bestPractice_prompt_name, format_prompt_name, 'JsonOutputParser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
