{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_temp = \"\"\" ### Instruction ###\n",
    "Act as a professional Software Engineer working with issue trackers like Jira or Azure DevOps.\n",
    "Working with these issue trackers, you must consider multiple text-based best practices to increase understandability and reduce time.\n",
    "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
    "The best practice to check is: \n",
    "{best_practice}\n",
    "\n",
    "### Context ###\n",
    "A ticket consists of multiple fields. You are provided with the fields and a short description for each field.\n",
    "Assignee: The person responsible to resolve the issue.\n",
    "Comments: Community discussion on the issue, including author, timestamp and content.\n",
    "Components: Project components to which the issue belongs.\n",
    "CreatedDate: The time and date the issue was created.\n",
    "Creator: The person who created the issue.\n",
    "Description: A detailed description of the issue.\n",
    "IssueLinks: A list of links to related issues.\n",
    "IssueType: The issue's purpose within the organization.\n",
    "Labels: Labels to which this issue relates.\n",
    "Priority: The issue importance in relation to other issues.\n",
    "Project: The parent project to which the issue belongs.\n",
    "Reporter: The person who found/reported the issue.\n",
    "Resolution: A record of the issue's resolution, once resolved or closed.\n",
    "ResolvedDate: The time and date the issue was resolved.\n",
    "Status: The stage the issue is currently at in its lifecycle.\n",
    "Summary: A brief one-line summary of the issue.\n",
    "TimeSpent: Amount of time spent working on the issue.\n",
    "VersionsAffected: The versions of the project affected by the issue.\n",
    "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
    "\n",
    "You will receive this ticket from an issue tracker in JSON format.\n",
    "Ticket: {ticket}\n",
    "\"\"\"\n",
    "init_prompt = PromptTemplate(template= init_temp, input_variables= [\"best_practice\", \"ticket\"])\n",
    "\n",
    "init_prompt.save(\"prompts/init/initPrompt_V1.1.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Prompt\n",
    "\n",
    "- Information misalingment\n",
    "- Information in description /comment, that parameters are outdated or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_temp = \"\"\"\n",
    "Best Practice: Update Missing/Outdated Fields\n",
    "Get contextual knowledge about the ticket through the 'Summary', 'Description', and 'Comments' fields.\n",
    "If you detect missing or outdated fields because you find something in the 'Summary', 'Description' and 'Comments' fields, update these fields.\n",
    "Don't return the revised ticket.\n",
    "Return a list with the changes you made with the addition of recommendations and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "update_prompt = PromptTemplate(template= update_temp, input_variables= [])\n",
    "update_prompt.save(\"prompts/update/updatePrompt_V1.2.0.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_temp = \"\"\"\n",
    "Best Practice: Summary Length\n",
    "Your Task is to check if the ticket summary is between {min} and {max} words.\n",
    "If the word count is in this range, return the original summary.\n",
    "Otherwise, recommend a new summary for the ticket.\n",
    "Please return only the summary string and nothing else.\n",
    "\"\"\"\n",
    "sumLen_prompt = PromptTemplate(template= sumLen_temp, input_variables= [\"min\", \"max\"])\n",
    "\n",
    "sumLen_prompt.save(\"prompts/summary/summaryLengthPrompt_V1.0.2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Length Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "descLen_temp = \"\"\"\n",
    "Best Practice: Description Length\n",
    "Your Task is to check if the ticket description is between {min} and {max} words.\n",
    "Ignore source code snippets or images in the description.\n",
    "If the word count is in this range, return the original description.\n",
    "Otherwise, recommend a new description for the ticket.\n",
    "Please return only the description string and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "descLen_prompt = PromptTemplate(template= descLen_temp, input_variables= [\"min\", \"max\"])\n",
    "\n",
    "descLen_prompt.save(\"prompts/description/descriptionLengthPrompt_V1.0.0.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
