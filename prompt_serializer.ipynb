{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_temp = \"\"\" ### Instruction ###\n",
    "Act as a professional {role} working with issue trackers like Jira or Azure DevOps.\n",
    "Working with these issue trackers, you have to consider multiple text-based best practices to increase understandability and reduce time.\n",
    "\"\"\"\n",
    "init_prompt = PromptTemplate(template= init_temp, input_variables= [\"role\"])\n",
    "init_prompt.save(\"prompts/init/init_prompt_V01.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_temp = \"\"\" ### Instruction ###\n",
    "Revise a ticket for compliance with these best practices and offer recommendations if needed.\n",
    "\"\"\"\n",
    "task_prompt = PromptTemplate(template= task_temp, input_variables= [])\n",
    "task_prompt.save(\"prompts/task/task_prompt_V01.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Kownledge Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not included because of missing description: Environment, Flagged, Parent, Rank, Sprint, TimeEstimateOriginal, TimeEstimateRemaining\n",
    "# not included, because only importanz for visualization: IssueId, EvoId, Updated\n",
    "context_temp = \"\"\" ### Context ###\n",
    "A ticket consist of multiple fields:\n",
    "Assignee: The person responsible to resolve the issue.\n",
    "Comments: Community discussion on the issue.\n",
    "Components: Project components to which the issue belongs.\n",
    "CreatedDate: The time and date the issue was created.\n",
    "Creator: The person who created the issue.\n",
    "Description: A detailed description of the issue.\n",
    "IssueLinks: A list of links to related issues.\n",
    "IssueType: The issue purpose within the organization.\n",
    "Labels: Labels to which this issue relates.\n",
    "Priority: The issue importance in relation to other issues.\n",
    "Project: The parent project to which the issue belongs.\n",
    "Reporter: The person who found/reported the issue.\n",
    "Resolution: A record of the issue's resolution, once resolved or closed.\n",
    "ResolvedDate: The time and date the issue was resolved.\n",
    "Status: The stage the issue is currently at in its lifecycle.\n",
    "Summary: A brief one-line summary of the issue.\n",
    "TimeSpent: Amount of time spent working on the issue.\n",
    "VersionsAffected: The versions of the project affected by the issue.\n",
    "VersionsFixed: Project versions in which the issue was (or will be) fixed.\n",
    "\n",
    "### Instruction ###\n",
    "Get contextual knowledge about the ticket.\n",
    "Ticket: {ticket}\n",
    "\n",
    "Return the unchanged ticket and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "context_prompt = PromptTemplate(template= context_temp, input_variables= [])\n",
    "context_prompt.save(\"prompts/context/context_prompt_V01.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Prompt\n",
    "\n",
    "- Information misalingment\n",
    "- Information in description /comment, that parameters are outdated or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Get contextual knowledge about the ticket through the 'Summary', 'Description' and 'Comments' field. If you detect missing or outdated fields, because you find something in the 'Summary', 'Description' and 'Comments' field give a recommendation for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Length Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumLen_temp = \"\"\" ### Context ###\n",
    "Best Practice: Summary Length\n",
    "\n",
    "### Instruction ###\n",
    "Your Task is to check if the summary of the ticket has between {min} and {max} words.\n",
    "If the word count is in this range return nothing.\n",
    "Else, return only a new summary in this range, based on the context of the ticket.\n",
    "\"\"\"\n",
    "sumLen_prompt = PromptTemplate(template= sumLen_temp, input_variables= [\"min\", \"max\"])\n",
    "sumLen_prompt.save(\"prompts/summary/sumLen_prompt_V01.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
